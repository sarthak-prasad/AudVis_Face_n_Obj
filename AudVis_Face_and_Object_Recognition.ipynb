{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudVis_Face_and Object_Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIx7SIvpovUf",
        "colab_type": "text"
      },
      "source": [
        "The project aims to develop a microcontroller based device in order to assist the Visually Impaired. \n",
        "This code was developed and tested on Google Colab and need some minor changes to be done before implementing on the actual hardware. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ1Em7axno74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install gTTS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQZnAQinreY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install dlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfBNE8wsnvHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT4IhwUDn1dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xnfe38mn4p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbj1eXKsn8_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install imageai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOWXSzpCqfiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a data set of known faces\n",
        "import face_recognition\n",
        "data_set = []\n",
        "a=['person1','person2']   # Name of a the known people\n",
        "\n",
        "data_set.append( face_recognition.load_image_file(\"/content/drive/My Drive/Colab_Files/Col_file/person1.jpg\") ) # Locations of the Faces of the known people\n",
        "data_set.append( face_recognition.load_image_file(\"/content/drive/My Drive/Colab_Files/Col_file/person2.jpg\") )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_kY-Q1Tk3iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the Face Recognition function\n",
        "import time\n",
        "from gtts import gTTS \n",
        "import IPython.display\n",
        "import os\n",
        "\n",
        "def Face_Rec_(img1,fl1) :\n",
        "    people = []\n",
        "    for dst in range (0,len(data_set)) :\n",
        "      for jhh in range (0,len(fl1)) :\n",
        "        biden_encoding = face_recognition.face_encodings(data_set[dst])[0]\n",
        "        unknown_encoding = face_recognition.face_encodings(img1)[jhh]\n",
        "        results = face_recognition.compare_faces([biden_encoding], unknown_encoding)\n",
        "        #print(results)\n",
        "        if results == [True] :\n",
        "          print(a[dst])\n",
        "          myobj = gTTS(text=str(a[dst]), lang='hi', slow=False) \n",
        "          aud = '/content/drnm.mp3'   # A file to store audio temporarily\n",
        "          myobj.save(aud) \n",
        "          IPython.display.display(IPython.display.Audio(aud,autoplay=True))\n",
        "          time.sleep(0.5)\n",
        "          os.remove('/content/drnm.mp3')\n",
        "          people.append(a[dst])\n",
        "              \n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XwTIZdkMXVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining Object Recognition Function\n",
        "import time\n",
        "from gtts import gTTS \n",
        "import IPython.display\n",
        "\n",
        "def Image_Obj_Reco( Location_of_test , Location_of_Result ) :\n",
        "    from imageai.Detection import ObjectDetection\n",
        "    import os\n",
        "\n",
        "    def CountFrequency(Name_of_Detected): \n",
        "          \n",
        "        # Creating an empty dictionary  \n",
        "        freq = {} \n",
        "        for items in Name_of_Detected: \n",
        "            freq[items] = Name_of_Detected.count(items) \n",
        "          \n",
        "        for key, value in freq.items(): \n",
        "            print (\"% d  % s detected\"%(value,key)) \n",
        "            fin_res_list = str(\"% d  % s detected\"%(value,key))\n",
        "            myobj = gTTS(text=fin_res_list, lang='en', slow=False) \n",
        "            aud = '/content/drt.mp3'   # A file to store audio temporarily\n",
        "            myobj.save(aud) \n",
        "            IPython.display.display(IPython.display.Audio(aud,autoplay=True))\n",
        "            time.sleep(3)\n",
        "            os.remove('/content/drt.mp3')\n",
        "\n",
        "    #print(os.getcwd())\n",
        "    execution_path = os.getcwd()\n",
        "    detector = ObjectDetection()\n",
        "    detector.setModelTypeAsRetinaNet()\n",
        "    detector.setModelPath( os.path.join(execution_path ,\"/content/drive/My Drive/Colab Notebooks/resnet50_coco_best_v2.0.1.h5\"))\n",
        "    detector.loadModel()\n",
        "    detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , Location_of_test), output_image_path=os.path.join(execution_path , Location_of_Result))\n",
        "\n",
        "    Name_of_Detected = []\n",
        "    for eachObject in detections:\n",
        "        print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )\n",
        "        Name_of_Detected.append(eachObject[\"name\"])\n",
        "\n",
        "\n",
        "    CountFrequency(Name_of_Detected)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIqeis5foXcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from gtts import gTTS \n",
        "import IPython.display\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "cam = cv2.VideoCapture(\"/content/drive/My Drive/Colab_Files/Col_file/test_video.webm\")  # Location of test video. This could be replaced by input from camera while using on actual hardware.\n",
        "fps = math.ceil(cam.get(cv2.CAP_PROP_FPS))                                        \n",
        "print(fps)\n",
        "time_span = 45\n",
        "ty=0  \n",
        "currentframe = 0\n",
        "\n",
        "try: \n",
        "      \n",
        "    # creating a folder named data \n",
        "    if not os.path.exists('frame_test'): \n",
        "        os.makedirs('frame_test') \n",
        "  \n",
        "    # if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of frame_test')\n",
        "try: \n",
        "      \n",
        "    # creating a folder named data \n",
        "    if not os.path.exists('res_'): \n",
        "        os.makedirs('res_') \n",
        "  \n",
        "    # if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of res_') \n",
        "  \n",
        "\n",
        "while(True) :  \n",
        "      \n",
        "    # reading from frame \n",
        "    ret,frame = cam.read() \n",
        "   \n",
        "    if ret: \n",
        "      if currentframe% (time_span*fps) == 1 :\n",
        "        name = '/content/frame_test/frame' + str(currentframe)  + '.jpg'\n",
        "        print ('Creating...' + name) \n",
        "      \n",
        "            # writing the extracted images \n",
        "        cv2.imwrite(name, frame) \n",
        "        j=currentframe\n",
        "        ad1= '/content/frame_test/frame' + str(j) + '.jpg'\n",
        "        img1= Image.open(ad1)\n",
        "\n",
        "        Location_of_test=\"/content/frame_test/frame\" + str(j) + \".jpg\"\n",
        "        Location_of_Result=\"/content/res_/\" + str(j) + \".jpg\"\n",
        "        Image_Obj_Reco(Location_of_test , Location_of_Result) \n",
        "        \n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "        img1 = face_recognition.load_image_file(ad1)\n",
        "        fl1 = face_recognition.face_locations(img1)\n",
        "        \n",
        "       \n",
        "        Face_Rec_(img1,fl1)\n",
        "        Op_image = cv2.imread(Location_of_Result)\n",
        "        cv2_imshow(Op_image)\n",
        "        \n",
        "      currentframe += 1\n",
        "   \n",
        "    else: \n",
        "        break\n",
        "    \n",
        "print(\"\\n\")    \n",
        "  \n",
        "print('ENDED')\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}